---
source_url: https://medium.com/data-science-at-microsoft/how-large-language-models-work-91c362f5b78f
date_created: 2025-01-22T15:08:45.262Z
---

# Notes: llm-primer

Here are comprehensive yet concise study notes on how Large Language Models (LLMs) work, based on the given webpage content:

## Understanding Large Language Models (LLMs)

### Background
- **Artificial Intelligence (AI)**: Deals with intelligent machines
- **Machine Learning (ML)**: Subfield of AI focused on pattern recognition in data
  - **Goal**: Discover patterns/relationships between input and output
  - Example: Predicting music genre (classification problem) based on tempo and energy
- **Deep Learning**: Field within ML focused on unstructured data like text and images
  - Uses **neural networks** inspired by the human brain

### Neural Networks
- Powerful ML models that can model complex relationships
- Consist of layers of connected "neurons" that process input to predict output
- Can be extremely large (e.g., ChatGPT has 176 billion neurons)

### Language Modeling
- **Language Modeling**: Learning to predict the next word in a sequence
  - Input: Sequence of words
  - Output: Next word (classification task with ~50,000 classes)
- Trained on massive text data from the internet, books, etc. (self-supervised learning)
- Learns grammar, syntax, and world knowledge during pre-training

### Natural Language Generation
- By predicting one word at a time, LLMs can generate text (Generative AI)
- Can sample from top likely words instead of always predicting the most likely (for creativity)

### GPT (Generative Pre-trained Transformer)
- **G**: Generative (trained on language generation task)
- **P**: Pre-trained (in multiple phases)
- **T**: Transformer (type of neural network architecture)

### Phases of LLM Training
1. **Pre-Training**: Learning to predict next word on massive data (acquires knowledge and abilities)
2. **Instruction Fine-Tuning**: Learning to follow instructions using instruction-response pairs
3. **Reinforcement from Human Feedback (RLHF)**: Aligning output with human values/preferences

### Emerging Abilities of LLMs
- **Zero-shot Learning**: Can perform new tasks by following instructions (without training examples)
- **Few-shot Learning**: Providing examples/demonstrations improves performance
- **Chain-of-Thought**: Allowing LLM to "think out loud" improves reasoning on complex tasks

### Mitigating Hallucinations
- LLMs may "hallucinate" and generate incorrect information
- Providing relevant context (e.g., Wikipedia article) can ground the LLM and improve accuracy

## Key Points
- **LLMs** are neural networks trained to predict the next word in a sequence
- Pre-training on massive data allows LLMs to acquire knowledge and abilities
- Fine-tuning and reinforcement align LLMs with human intentions
- LLMs show emerging abilities like zero-shot learning and chain-of-thought reasoning
- Providing context and examples can improve LLM performance and mitigate hallucinations

---
Generated by Web Notes AI
